
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
% the code below specifies where the figures are stored
\graphicspath{{1/figures/}}

\chapter{Introduction}
\label{chp:introduction}

% Information age
It goes without saying that we live in the Age of Information, our day to day experiences awash in a flood of data.
As a society, we buy, sell, consume and produce information in unprecedented quantities.
% More data than anyone can handle
Given the accelerating rate at which digital information is created, one of the fundamental challenges facing the modern world is simply the navigation of it.
% Google bitches
The quintessential response to this challenge is embodied by Google, whose collective \emph{raison d'\^etre} is the organization and indexing of the world's information.
To appreciate the value and reach of this technology, one only needs to imagine how difficult it is to browse the Internet without a search engine.

 % is a significant research effort behind the development of computational methods and algorithms to help make information universally accessible and useful. %, and this is particularly evident in the realm of music.

% Information overload, yo

% This domain is broadly referred to as \emph{information retrieval} (IR), and has grown rapidly in recent years, with various subdomains coalescing around application-specific topics.

Understandably, a variety of specialized disciplines have formed under the auspices of developing systems to help people navigate and ultimately make sense of massive amounts of information.
Coalescing around the turn of the century, music informatics is one such instance, drawing from several diverse fields including electrical engineering, music psychology, computer science, machine learning, and music theory, among others.
Now encompassing a wide spectrum of application areas and the kinds of data considered---from audio and text to album covers and online social interactions---music informatics can be broadly defined as the study of information related to, or is a result of, musical activity.

% IR Formulation
At a high level, tackling this problem of information overload can be formulated as a retrieval problem: from a large collection of music items, how does one find those relevant to a given query?
To answer this question, any system, computational or otherwise, must typically solve two related problems: describe the \emph{intrinsic} qualities of an item in isolation, and determine the \emph{extrinsic} relationships between those in a collection.
Emphasizing this distinction, the former focuses on absolute representation, whereas the latter is concerned with relative associations.
% Human provided descriptions and relationships
To date, the most successful approaches to large-scale information systems leverage human-provided \emph{signals} to achieve rich representations of content.
% Human signals about the content
For example, the Netflix Challenge\footnote{netflix link} ---an open contest to find the best system for automatically predicting a user's enjoyment of a movie--- was built exclusively on movie ratings provided by a large collection of other users.
% Links between content
On the other hand, Google's \emph{PageRank} algorithm\footnote{pagerank link} associates websites based on how users have linked different pages together, thus facilitating the process of traversing this web of information.
% Importantly, in this paradigm, it is of little consequence what a document actually \emph{is} or represents once a user is able to provide a compact description of it.

% Music is a different ballgame, y'all; document description is wicked hard.
While this strategy of leveraging human signals has proven successful in large-scale music recommendation, such as Pandora Radio\footnote{pandora website}, its application to more general music information problems is fundamentally limited, manifesting in three related ways.
First, human signals commonly used in such systems ---clicks, likes, views and shares--- are easily captured as a natural by-product of the typical user interaction paradigm.
It is one thing to obtain a simple ``thumbs up'' for a song; it is quite another to ask that same user to provide a chord transcription of it.
Second, manual music description may require a high degree of expertise or effort to perform.
The average music listener is not capable of accurate chord transcription, whether or not she possesses the time or willingness to attempt it.
Finally, even given the skill, motivation, and infrastructure to manually describe music, this approach cannot scale to \emph{all} music content, now or in the future.
The Music Genome Project, for example, has managed to manually annotate some 1M commercial recordings, at a pace of 20-30 minutes per track; the iTunes Music Store, however, now offers over 28M tracks for purchase.
To illustrate how vast this discrepancy is, consider the following: even assuming the lower bound of 20 minutes, it would still take one sad individual \emph{1,000 years} of non-stop annotation to close that gap.
More importantly, this only considers commercial music recordings, neglecting amateur or unpublished content, the addition of which makes this goal even more insurmountable.
Given the sheer impossibility for humans to meaningfully describe all recorded music, now and in the future, truly scalable music information systems will require good computational algorithms to perform this task.

% Music description is good, state of the art is bad
Thus, the development of computational systems to describe music signals, referred to as machine listening or computer audition, is both a valuable and fascinating problem.
In addition to facilitating the search and retrieval of large music collections, automatic systems capable of expert-level music description are invaluable to users who are unable to perform the task themselves, e.g. music transcription.
Notably, this problem is also very much unsolved, and given an apparent decceleration of progress, some in the field of music informatics have begun to question the efficacy of traditional research methods.
% Statement of the issues?
Simultaneously, in the related fields of computer vision and automatic speech recognition, a branch of machine learning, referred to as \emph{deep learning}, has shown great performance in various domains, toppling many long-standing benchmarks.
On closer inspection, one recognizes considerable conceptual overlap between deep learning and conventional music information systems, further encouraging this promising union.

% Research goal
Synthesizing these observations, the goal of this study is the exploration of deep learning methods as a general approach to the design of machine listening systems for music applications.
More specifically, the proposed research method proceeds thusly:
first, it is necessary to assess why progress in content-based MIR may have stalled, and, in doing so, identify possible deficiencies in this methodology;
having built an understanding, standard approaches to music signal processing are reformulated in the language and concepts of deep learning, and subsequently applied to classic MIR problems;
finally, the performance and behavior of these deep learning systems is deconstructed in order to illustrate the advantages and challenges inherent to this paradigm.


\section{Scope of this Study}
\label{sec:scope}

% Functionally model intelligent behavior
% how to judge whether or not the description is good? and what is good?
% hinges on how quality is defined
% assessment is driven by how the system behaves compared to

This study explores the use of deep learning in the development of systems for automatic music description.
Consistent with the larger body of machine perception research, the work presented here aims to computationally model the relationship between stimuli and observations made by an intelligent agent.
In this case, ``stimuli'' are digital signals representing acoustic waves, e.g. sound, ``observations'' are semantic descriptions in a particular namespace, e.g. timbre or harmony, and the agent being modeled is a intelligent human, e.g. an expert music listener.
In practice, the namespace of descriptions considered is constrained to a particular task or application, such as instrument recognition or chord estimation.

Furthermore, if the relationship between stimuli and observation is not a function of the agent, this mapping is said to be ``objective''.
Objective relationships are those that are true absolutely by definition, such as the statement ``A C Major triad consists of the pitches C, E, and G.''
Elaborating, all sufficiently capable agents should always produce the same output given the same input.
Discrepancies between observations of the same stimuli are understood as one or more of these perspectives being erroneous, resulting from either simple error or a deficiency of knowledge.
For objective relationships, the \emph{quality} of a model in question is determined by how well it is able to reproduce the ``correct'' expert perspective exactly.

Conversely, input-output relationships that \emph{are} a function of the agent are said to be ``subjective''.
In contrast to the objective case, which is fundamentally concerned with \emph{facts}, a subjective observation is ultimately an \emph{opinion}.
As such, an opinion can only be true or false insofar as it is held by a competent agent.
This is embodied, for example, in the statement ``That sounds like a saxophone.''
Whether or not the stimuli originated from a saxophone is arguably of little consequence; an agent made the observation, and thus it is in some sense valid.
Assessing the quality of a computational model at a subjective task must therefore take one of two slightly different formulations.
The first transforms a subjective problem to an objective one by considering the perspective of single agent as truth, and thus the quality of a model is a function of how well it can mimic the behavior of that \emph{one} agent.
Alternatively, the other approach attempts to determine whether or not a model makes observations on par with other competent agents
%\footnote{It has been said that ``Reality is a shared delusion, albeit a persistent one.''},
, forming the premise of Alan Turing's test for intelligence.
In this view, a computational system's capacity to perform some intelligent task is measured by its ability to convince other humans that it is equally competent.

The notions of, and inherent conflict between, objectivity and subjectivity in audition and music perception are central to the challenge posed by the computational modeling of it.
Arguably most facets of music perception are subjective and vary in degree from task to task.
However, while a Turing test might be better suited toward evaluating the quality or usability of some computational model, the human involvement required by such assessments make them prohibitively costly in both time and money to conduct with any regularity.
As a result, conventional research methodolgy in engineering and computer science greatly prefers \emph{quantitative} evaluation as a proxy to \emph{qualitative} responses collected from human subjects.
Typically quantitative methods proceed by collecting some number of input-output pairs from one or more human subjects \emph{first} and treating this data sample as absolute or ``ground'' truth.
Therefore, regardless of whether or not a given task is actually objective, it is a significant simplification in methodology to treat it as one.

This is all to say that the validity and quality of a music description is ultimately determined by an objective fitness measure, not necessarily out of correctness but rather tractability and practicality.
Thus, any quantitative measure is only valid so long as this assumption of objectivity is not invalidated.


\section{Motivation}
% Significance


The proposed research is primarily motivated by two complementary observations:
one, large scale music signal processing systems are now necessary to help humans navigate and make sense of an ever-increasing volume of music information;
two ---and, more notably, the specific problem this work seeks to address--- the conventional research tradition in content-based music information retrieval is yielding diminishing returns, despite many research areas remaining unsolved.

In the most immediate sense, the proposed research will develop systems to tackle various applications in music informatics.
This will at least serve to explore an alternative approach to conventional problems in the field.
Based on preliminary results, there is good reason to believe that deep learning may in fact push the state of the art in some, if not all, of the tasks considered.
Sufficiently advanced systems could be deployed in end-user applications, such as navigating music libraries or computer-aided composition and performance.

A thorough exploration and successful extension of deep learning to music signal processing has the significant potential to encourage others in the community to also conduct research in this area.
The impacts of such a development could be far reaching, but there are two of particular note.
First and foremost, drawing attention to a promising, but otherwise uncharted, research area opens new opportunities for fresh ideas and perspectives.
Additionally, deep learning automatically optimizes a system to the data on hand, accelerating research and simplifying the overall design problem.
Therefore these methods yield flexible systems that can easily adapt to new data as well as new \emph{problems}, allowing researchers to seek out novel, exciting applications.

Beyond the scope of music informatics, deep learning research in the context of a different domain, with its own unique challenges, is likely to produce discoveries beneficial to the broad audience of computer science and information processing.
One such area where this is likely to occur is in the handling of time-domain signals and sequences.
Computer vision, the field in which most breakthroughs in deep learning have occurred, mostly ignores the temporal aspect of images.
Some effort has explored this in motion capture and natural language processing, as we will discuss in the following chapter, but the tradition of music signal processing draws heavily from digital signal theory, a field of study focused almost entirely on an analytical understanding of time.

Therefore, this work offers several potential contributions, both theoretical and practical, to a diverse audience, spanning users of technology, music informatics, and the deep learning community on the whole.


\section{Dissertation Outline}
\label{sec:outline}
\begin{description}

\item Chapter \ref{chp:context} reviews the current state of affairs in music informatics research, providing context for this work.

\item Chapter \ref{chp:deep_learning} surveys the body of literature in deep learning, outlining core concepts and definitions.

\item Chapter \ref{chp:timbre_sim} explores the application of deep learning toward the development of objective timbre similarity spaces.

\item Chapter \ref{chp:chord_estimation} considers the application of deep learning toward automatic chord estimation, as a means to both improve the state of the art and better understand the task at hand.

\item Chapter \ref{chp:guitar} extends this chord estimation efforts to directly estimate human-readable representations in the form of guitar tablature.

\item Chapter \ref{chp:reproducibility} documents the software contributions resulting from this study, contributing to the greater cause of reproducible research efforts.

\item Chapter \ref{chp:conclusion} concludes this thesis.
There will be tables and chairs, there'll be pony rides and dancing bears, there'll even be a band.

\end{description}

\section{Contributions}
The primary contributions of this dissertation are listed below:

\begin{itemize}
  \onehalfspacing
\item Carrot cake macaroon brownie chupa chups powder sesame snaps bear claw souffle biscuit.
\item Sweet roll chocolate chocolate cake.
\end{itemize}

\section{Associated Publications by the Author}

This thesis covers much of the work presented in the publications listed below:

\subsection{Peer-Reviewed Articles}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\vspace{1em}
\begin{itemize}
\onehalfspacing
\item Sugar plum jelly beans cookie tootsie roll jelly-o.
\item Tootsie roll sugar plum cotton candy pastry chocolate cake pudding oat cake gummi bears.
\end{itemize}

\subsection{Peer-Reviewed Conference Papers}
\vspace{1em}
\begin{itemize}
\onehalfspacing
\item Cheesecake pudding marzipan gingerbread cheesecake oat cake applicake.
\item  Dragee marzipan unerdwear.com powder icing croissant pastry.
\item  Dessert macaroon sweet roll macaroon wafer topping croissant.

\end{itemize}

