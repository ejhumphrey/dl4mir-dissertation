
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
% the code below specifies where the figures are stored
\graphicspath{{1/figures/}}

\chapter{Introduction}
\label{chp:introduction}

% Information age
It goes without saying that we live in the Age of Information, our day to day experiences awash in a flood of data.
As a society, we buy, sell, consume and produce information in unprecedented quantities.
% More data than anyone can handle
Given the accelerating rate at which information is created, one of the fundamental challenges facing the modern world is simply making sense of all this data.
% Google bitches
The quintessential response to this obstacle is embodied by Google, whose collective \emph{raison d'\^etre} is the organization and indexing of the world's information.
To appreciate the value and reach of this technology, one only needs to imagine how difficult it would be to browse the Internet without a search engine.

 % is a significant research effort behind the development of computational methods and algorithms to help make information universally accessible and useful. %, and this is particularly evident in the realm of music.

% Information overload, yo

% This domain is broadly referred to as \emph{information retrieval} (IR), and has grown rapidly in recent years, with various subdomains coalescing around application-specific topics.

Understandably, a variety of specialized disciplines have formed under the auspices of developing systems to help people navigate and understand massive amounts of information.
Coalescing around the turn of the century, music informatics is one such instance, drawing from several diverse fields including electrical engineering, music psychology, computer science, machine learning, and music theory, among others.
Now encompassing a wide spectrum of application areas and the kinds of data considered---from audio and text to album covers and online social interactions---music informatics can be broadly defined as the study of information related to, or is a result of, musical activity.

% IR Formulation
At a high level, tackling this problem of ``information overload'' in music is captured by a simple, general analogy: how exactly \emph{does} one find a needle in a haystack?
To answer this question, any system, computational or otherwise, must solve two related problems:
first, it is necessary to describe the intrinsic qualities of the item of interest, e.g. a needle is metal, sharp, thin, etc;
and second, it is necessary to evaluate the extrinsic relationships between items to determine relevance.
A piece of hay is certainly not a needle, for example, but is a pin close enough?
Along what criteria might we gauge similarity, or group objects into distinct classes?
Emphasizing the distinction, \emph{description} focuses on absolute representation, whereas \emph{comparison} is concerned with relative associations.

% Human provided descriptions and relationships
To date, the most successful approaches to large-scale information systems leverage human-provided signals to achieve rich content descriptions.
Building on top of robust representations simplifies the problem greatly, and good progress has been made toward the development of useful applications.
% Human signals about the content
For example, the Netflix Challenge\footnote{netflix link} ---an open contest to find the best system for automatically predicting a user's enjoyment of a movie--- was built exclusively on movie ratings contributed by a large collection of other users.
% Links between content
Similarly, Google's \emph{PageRank} algorithm\footnote{pagerank link} associates websites based on how users have linked different pages together, thus facilitating the process of traversing the world's information.

% Music is a different ballgame, y'all; document description is wicked hard.
While this strategy of leveraging manual content description has proven successful in large-scale music recommendation, such as Pandora Radio\footnote{pandora website}, its application to more general music information problems is fundamentally limited, manifesting in three related ways.
First, human-provided information commonly used in such systems ---clicks, likes, listens or shares--- are easily captured as a natural by-product of the typical user interaction paradigm.
It is one thing to obtain a simple ``thumbs up'' for a song; it is quite another to ask that same user to provide a chord transcription of it.
Second, manual music description may require a high degree of expertise or effort to perform.
The average music listener is not capable of accurate chord transcription, whether or not she possesses the time or willingness to attempt it.
Finally, even given the skill, motivation, and infrastructure to manually describe music, this approach cannot scale to \emph{all} music content, now or in the future.
The Music Genome Project, for example, has managed to manually annotate some 1M commercial recordings, at a pace of 20-30 minutes per track; the iTunes Music Store, however, now offers over 28M tracks for purchase.
To illustrate how vast this discrepancy is, consider the following: even assuming the lower bound of 20 minutes, it would still take one sad individual \emph{1,000 years} of non-stop annotation to close that gap.
More importantly, this only considers commercial music recordings, neglecting amateur or unpublished content, the addition of which makes this goal even more insurmountable.
Given the sheer impossibility for humans to meaningfully describe all recorded music, now and in the future, truly scalable music information systems will require good automatic systems to perform this task.

% Music description is good, state of the art is bad
Thus, the development of computational systems to describe music signals, a flavor of \emph{computer audition} referred to as content-based music informatics, is both a valuable and fascinating problem.
In addition to facilitating the search and retrieval of large music collections, automatic systems capable of expert-level music description are invaluable to users who are unable to perform the task themselves, e.g. music transcription.
Notably, this problem is also very much unsolved, and given an apparent decceleration of progress, some in the field of music informatics have begun to question the efficacy of traditional research methods.
% Statement of the issues?
Simultaneously, in the related fields of computer vision and automatic speech recognition, a branch of machine learning, referred to as \emph{deep learning}, has shown great performance in various domains, toppling many long-standing benchmarks.
On closer inspection, one recognizes considerable conceptual overlap between deep learning and conventional music signal processing systems, further encouraging this promising union.

% Research goal
Synthesizing these observations, this study explores deep learning as a general approach to the design of computer audition systems for music applications.
More specifically, the proposed research method proceeds thusly:
first, methods and trends in content-based music informatics are reviewed in an effort to understand why progress in this domain may be decellerating, and, in doing so, identify possible deficiencies in this methodology;
standard approaches to music signal processing are then reformulated in the language and concepts of deep learning, and subsequently applied to classic music informatics problems;
finally, the behavior of these deep learning systems is deconstructed in order to illustrate the advantages and challenges inherent to this paradigm.


\section{Scope of this Study}
\label{sec:scope}

% Functionally model intelligent behavior
% how to judge whether or not the description is good? and what is good?
% hinges on how quality is defined
% assessment is driven by how the system behaves compared to

This study explores the use of deep learning in the development of systems for automatic music description.
Consistent with the larger body of machine perception research, the work presented here aims to computationally model the relationship between stimuli and observations made by an intelligent agent.
In this case, ``stimuli'' are digital signals representing acoustic waves, e.g. sound, ``observations'' are semantic descriptions in a particular namespace, e.g. timbre or harmony, and the agent being modeled is a intelligent human, e.g. an expert music listener.
In practice, the namespace of descriptions considered is constrained to a particular task or application, such as instrument recognition or chord estimation.

Furthermore, if the relationship between stimuli and observation is not a function of the agent, this mapping is said to be ``objective''.
Objective relationships are those that are true absolutely by definition, such as the statement ``A C Major triad consists of the pitches C, E, and G.''
Elaborating, all sufficiently capable agents should always produce the same output given the same input.
Discrepancies between observations of the same stimuli are understood as one or more of these perspectives being erroneous, resulting from either simple error or a deficiency of knowledge.
For objective relationships, the \emph{quality} of a model is determined by how often it is able to produce ``right'' answers to the questions being asked.

Conversely, input-output relationships that \emph{are} a function of the agent are said to be ``subjective''.
In contrast to the objective case, which is fundamentally concerned with \emph{facts}, a subjective observation is ultimately an \emph{opinion}.
As such, an opinion can only be true or false insofar as it is held by a competent agent.
This is embodied, for example, in the statement ``That sounds like a saxophone.''
Whether or not the stimuli originated from a saxophone is actually irrelevant; an agent made the observation, and thus it is in some sense valid.
Assessing the quality of a computational model at a subjective task must therefore take one of two slightly different formulations.
The first transforms a subjective problem to an objective one by considering the perspective of single agent as truth, and thus the quality of a model is a function of how well it can mimic the behavior of that \emph{one} agent.
Alternatively, the other approach attempts to determine whether or not a model makes observations on par with other competent agents. % e.g. does a system \emph{behave} like other intelligent agents.
In this view, a computational system's capacity to perform some intelligent task is measured by its ability to convince humans that it is competent (or not) in human ways.

The notions of, and inherent conflict between, objectivity and subjectivity in audition and music perception are central to the challenge posed by the computational modeling of it.
Arguably most facets of music perception are subjective and vary in degree from task to task.
However, while subjective evaluation might be better suited toward measuring the quality or usability of some computational system, the human involvement required by such assessments make them prohibitively costly in both time and money to conduct with any regularity.
As a result, conventional research methodolgy in engineering and computer science greatly prefers \emph{quantitative} evaluation as a proxy to \emph{qualitative} responses collected from human subjects.
Typically quantitative methods proceed by collecting some number of input-output pairs from one or more human subjects \emph{first} and treating this data sample as absolute or ``ground'' truth.
Thus, regardless of whether or not a given task is actually objective, it is a significant simplification in methodology to treat it as one.

This is all to say that the validity and quality of a music description is ultimately determined by an objective fitness measure, not necessarily out of correctness but rather tractability.
Therefore, any quantitative measure is only valid insofar as the assumption of objectivity is as well.


\section{Motivation}
% Significance


The proposed research is primarily motivated by two complementary observations:
one, large scale music signal processing systems are now necessary to help humans navigate and make sense of an ever-increasing volume of music information;
two ---and, more notably, the specific problem this work seeks to address--- the conventional research tradition in content-based music information retrieval is yielding diminishing returns, despite many research areas remaining unsolved.

In the most immediate sense, the proposed research will develop systems to tackle various applications in music informatics.
This will at least serve to explore an alternative approach to conventional problems in the field.
Based on preliminary results, there is good reason to believe that deep learning may in fact push the state of the art in some, if not most, applications in automatic music description.
Sufficiently advanced systems could be deployed in end-user applications, such as navigating music libraries or computer-aided composition and performance.

A thorough exploration and successful extension of deep learning to music signal processing has the significant potential to encourage others in the community to also conduct research in this area.
The impacts of such a development could be far reaching, but there are two of particular note.
First and foremost, drawing attention to a promising, but otherwise uncharted, research area opens new opportunities for fresh ideas and perspectives.
Additionally, deep learning automatically optimizes a system to the data on hand, accelerating research and simplifying the overall design problem.
Therefore these methods yield flexible systems that can easily adapt to new data as well as new \emph{problems}, allowing researchers to seek out novel, exciting applications.

Beyond the scope of music informatics, deep learning research in the context of a different domain, with its own unique challenges, is likely to produce discoveries beneficial to the broad audience of computer science and information processing.
One such area where this is likely to occur is in the handling of time-domain signals and sequences.
Computer vision, the field in which most breakthroughs in deep learning have occurred, mostly ignores the temporal aspect of images.
Some effort has explored this in motion capture and natural language processing, as will be discussed later, but the tradition of music signal processing draws heavily from digital signal theory, a field of study focused almost entirely on an analytical understanding of time.

Therefore, this work offers several potential contributions, both theoretical and practical, to a diverse audience, spanning users of technology, music informatics, and the deep learning community on the whole.


\section{Dissertation Outline}
\label{sec:outline}
\begin{description}

\item Chapter \ref{chp:context} reviews the current state of affairs in music informatics research, providing context for this work.

\item Chapter \ref{chp:deep_learning} surveys the body of literature in deep learning, outlining core concepts and definitions.

\item Chapter \ref{chp:timbre_sim} explores the application of deep learning toward the development of objective timbre similarity spaces.

\item Chapter \ref{chp:chord_estimation} considers the application of deep learning toward automatic chord estimation, as a means to both improve the state of the art and better understand the task at hand.

\item Chapter \ref{chp:guitar} extends this chord estimation efforts to directly estimate human-readable representations in the form of guitar tablature.

\item Chapter \ref{chp:reproducibility} documents the software contributions resulting from this study, contributing to the greater cause of reproducible research efforts.

\item Chapter \ref{chp:conclusion} concludes this thesis.
There will be tables and chairs, there'll be pony rides and dancing bears, there'll even be a band.

\end{description}

\section{Contributions}
The primary contributions of this dissertation are listed below:

\begin{itemize}
  \onehalfspacing
\item Carrot cake macaroon brownie chupa chups powder sesame snaps bear claw souffle biscuit.
\item Sweet roll chocolate chocolate cake.
\end{itemize}

\section{Associated Publications by the Author}

This thesis covers much of the work presented in the publications listed below:

\subsection{Peer-Reviewed Articles}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\vspace{1em}
\begin{itemize}
\onehalfspacing
\item Sugar plum jelly beans cookie tootsie roll jelly-o.
\item Tootsie roll sugar plum cotton candy pastry chocolate cake pudding oat cake gummi bears.
\end{itemize}

\subsection{Peer-Reviewed Conference Papers}
\vspace{1em}
\begin{itemize}
\onehalfspacing
\item Cheesecake pudding marzipan gingerbread cheesecake oat cake applicake.
\item  Dragee marzipan unerdwear.com powder icing croissant pastry.
\item  Dessert macaroon sweet roll macaroon wafer topping croissant.

\end{itemize}

