
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
% the code below specifies where the figures are stored
\graphicspath{{1/figures/}}

\chapter{Introduction}
\label{chp:introduction}

% Information age
It goes without saying that we live in the Age of Information, our day to day experiences awash in a flood of data.
As a society, we buy, sell, consume and produce information in unprecedented quantities.
% More data than anyone can handle
Given the accelerating rate at which digital information is created, one of the fundamental challenges facing the modern world is simply the navigation of it.
% Google bitches
The quintessential response to this challenge is embodied by Google, whose collective \emph{raison d'\^etre} is the organization and indexing of the world's information.
To appreciate the value and reach of this technology, one only needs to imagine how difficult it is to browse the Internet without a search engine.

 % is a significant research effort behind the development of computational methods and algorithms to help make information universally accessible and useful. %, and this is particularly evident in the realm of music.

% Information overload, yo

% This domain is broadly referred to as \emph{information retrieval} (IR), and has grown rapidly in recent years, with various subdomains coalescing around application-specific topics.

Understandably, a variety of specialized disciplines have formed under the auspices of developing systems to help people navigate and ultimately make sense of massive amounts of information.
Coalescing around the turn of the century, music informatics is one such instance, drawing from several diverse fields including electrical engineering, music psychology, computer science, machine learning, and music theory, among others.
Now encompassing a wide spectrum of application areas and the kinds of data considered---from audio and text to album covers and online social interactions---music informatics can be broadly defined as the study of information related to, or is a result of, musical activity.

% IR Formulation
At a high level, tackling this problem of information overload can be formulated as a retrieval problem: from a large collection of music items, how does one find those relevant to a given query?
To answer this question, any system, computational or otherwise, must typically solve two related problems: describe the \emph{intrinsic} qualities of an item in isolation, and determine the \emph{extrinsic} relationships between those in a collection.
Emphasizing this distinction, the former focuses on absolute representation, whereas the latter is concerned with relative associations.
% Human provided descriptions and relationships
To date, the most successful approaches to large-scale information systems leverage human-provided \emph{signals} to achieve rich representations of content.
% Human signals about the content
For example, the Netflix Challenge\footnote{netflix link} ---an open contest to find the best system for automatically predicting a user's enjoyment of a movie--- was built exclusively on movie ratings provided by a large collection of other users.
% Links between content
On the other hand, Google's \emph{PageRank} algorithm\footnote{pagerank link} associates websites based on how users have linked different pages together, thus facilitating the process of traversing this web of information.
% Importantly, in this paradigm, it is of little consequence what a document actually \emph{is} or represents once a user is able to provide a compact description of it.

% Music is a different ballgame, y'all; document description is wicked hard.
While this strategy of leveraging human signals has proven successful in large-scale music recommendation, such as Pandora Radio\footnote{pandora website}, its application to more general music information problems is fundamentally limited, manifesting in three related ways.
First, human signals commonly used in such systems ---clicks, likes, views and shares--- are easily captured as a natural by-product of the typical user interaction paradigm.
It is one thing to obtain a simple ``thumbs up'' for a song; it is quite another to ask that same user to provide a chord transcription of it.
Second, manual music description may require a high degree of expertise or effort to perform.
The average music listener is not capable of accurate chord transcription, whether or not she possesses the time or willingness to attempt it.
Finally, even given the skill, motivation, and infrastructure to manually describe music, this approach cannot scale to \emhp{all} music content, now or in the future.
The Music Genome Project, for example, has managed to manually annotate some 1M commercial recordings, at a pace of 20-30 minutes per track; the iTunes Music Store, however, now offers over 28M tracks for purchase.
To illustrate how vast this discrepancy is, consider the following: even assuming the lower bound of 20 minutes, it would still take one sad individual \emph{1,000 years} of non-stop annotation to close that gap.
More importantly, this only considers commercial music recordings, neglecting amateur or unpublished content, the addition of which makes this goal even more insurmountable.
Given the sheer impossibility for humans to meaningfully describe all recorded music, now and in the future, truly scalable music information systems will require good computational algorithms to perform this task.

% Music description is good, state of the art is bad
Thus, the development of computational systems to describe music signals, referred to as machine listening or computer audition, is both a valuable and fascinating problem.
In addition to facilitating the search and retrieval of large music collections, automatic systems capable of expert-level music description are invaluable to users who are unable to perform the task themselves, e.g. music transcription.
Notably, this problem is also very much unsolved, and given an apparent decceleration of progress, some in the field of music informatics have begun to question the efficacy of traditional research methods.
% Statement of the issues?
Simultaneously, in the related fields of computer vision and automatic speech recognition, a branch of machine learning, referred to as \emph{deep learning}, has shown great performance in various domains, toppling many long-standing benchmarks.
On closer inspection, one recognizes considerable conceptual overlap between deep learning and conventional music information systems, further encouraging this promising union.

% Research goal
Synthesizing these observations, the goal of this study is the exploration of deep learning methods as a general approach to the design of machine listening systems for music applications.
More specifically, the proposed research method proceeds thusly:
first, it is necessary to assess why progress in content-based MIR may have stalled, and, in doing so, identify possible deficiencies in this methodology;
having built an understanding, standard approaches to music signal processing are reformulated in the language and concepts of deep learning, and subsequently applied to classic MIR problems;
finally, the performance and behavior of these deep learning systems is deconstructed in order to illustrate the advantages and challenges inherent to this paradigm.


\section{Scope of this Study}
\label{sec:scope}

% Computationally model music descriptions
% How far can you get from an audio signal alone
% Input-output systems / functions
% Behaviorist view of intelligence
% Quantitative evaluation; how well can these input / output pairs be modeled.
%

This study focuses on computationally modeling the relationship between stimuli (inputs) and observable behaviors (outputs) of a given system.
Here, ``inputs'' are digital signals representing acoustic waves, or sounds, and ``outputs'' correspond to semantic descriptions of these observations in a particular namespace, e.g. chords.
Typically, although not necessarily, the system being modeled is that of an intelligent human behavior, e.g. recognizing chords from music audio.
Note that this formulation attempts to characterize any complex system as a \emph{function}, consistent with a behaviorist view of intelligence.
As such, a computational model of some intelligent act might be deemed satisfactory if it passes a sort of ``Turing test'', where the responses of a machine are comparable to that of a human.

% What does this mean for the computational model
Given the clear relationship to the field of artificial intelligence (AI), it is a useful and necessary step to address the limits of this perspective, sucicntly captured by John Searle's famous thought experiment \cite{Searle1960?}.
Imagine an enclosed room, where messages in a strange language arrive on paper in one mailbox, and responses returned through another.
It is accompanied by a rather verbose instruction manual, enabling one unfamiliar with this particular language to reply appropriately.
Though a clueless individual operating in this room might be able to carry on a perfectly coherent dialogue with someone, perhaps even convincing the outsider of comprehension, one would not claim this system to be ``intelligent'' due to a lack of \emph{intentionality} and \emph{comprehension}.
Therefore, ``strong'' AI requires one not only acts intelligently, but does so with purpose and expectation.
It is important, then, to recognize that the notion of ``behaving intelligently'' is not synonomous with ``being intelligent'', and the work here focuses entirely on the former.

Music signal processing systems are fundamentally limited by two closely related issues: objective truth and subjective agreement.
The conceptual abstraction inherent to music spans the most literal events ---a drum is struck--- to the most intangible ---a \emph{sad} melody is performed.
Therefore, any attempt to semantically describe music is constrained to the extent that the response can be consistently derived from the signal alone.

This is compounded by the observation that such information processing systems are not necessarily  performing the task at hand, so much as attempting to mimic the decision making processes of one or more humans.
However, the perception of music is predominantly a subjective experience; seemingly well-defined tasks in music informatics are often those where the majority of listeners share a common experience.
As a result, many annotators for a highly subjective task, such as genre identification, can lead to situations where the ground-truth can conflict with itself.
Therefore, performance ceilings are often lower than 100\%, but are otherwise unknown in practice.
Though some might contend that this amounts to labeling error, the problem faced by multiple valid interpretations is especially characteristic to music and must be acknowledged.


% The computational models considered here exhibit three important and related properties.
% They are deterministic, time-invariant, and respond precisely to a given input.
% In other words, the same input will always yield the same input, regardless of when it processed.
% concepts like ``learning'' are used in the metaphorical sense.
% and often implicitly build on two assumptions: that such mappings can be obtained, and that generalization ---accurate outputs for never-before-seen inputs--- is synonymous with interpolation.
% The limits of this research trajectory are intrinsically linked to the extent that this is or can be a valid problem formulation, but recent progress has aptly demonstrated that the state of the art is well within these bounds.



\section{Motivation}
% Significance


The proposed research is primarily motivated by two complementary observations:
one, large scale music signal processing systems are now necessary to help humans navigate and make sense of an ever-increasing volume of music information;
two ---and, more notably, the specific problem this work seeks to address--- the conventional research tradition in content-based music information retrieval is yielding diminishing returns, despite many research areas remaining unsolved.

In the most immediate sense, the proposed research will develop systems to tackle various applications in music informatics.
This will at least serve to explore an alternative approach to conventional problems in the field.
Based on preliminary results, there is good reason to believe that deep learning may in fact push the state of the art in some, if not all, of the tasks considered.
Sufficiently advanced systems could be deployed in end-user applications, such as navigating music libraries or computer-aided composition and performance.

A thorough exploration and successful extension of deep learning to music signal processing has the significant potential to encourage others in the community to also conduct research in this area.
The impacts of such a development could be far reaching, but there are two of particular note.
First and foremost, drawing attention to a promising, but otherwise uncharted, research area opens new opportunities for fresh ideas and perspectives.
Additionally, deep learning automatically optimizes a system to the data on hand, accelerating research and simplifying the overall design problem.
Therefore these methods yield flexible systems that can easily adapt to new data as well as new \emph{problems}, allowing researchers to seek out novel, exciting applications.

Beyond the scope of music informatics, deep learning research in the context of a different domain, with its own unique challenges, is likely to produce discoveries beneficial to the broad audience of computer science and information processing.
One such area where this is likely to occur is in the handling of time-domain signals and sequences.
Computer vision, the field in which most breakthroughs in deep learning have occurred, mostly ignores the temporal aspect of images.
Some effort has explored this in motion capture and natural language processing, as we will discuss in the following chapter, but the tradition of music signal processing draws heavily from digital signal theory, a field of study focused almost entirely on an analytical understanding of time.

Therefore, this work offers several potential contributions, both theoretical and practical, to a diverse audience, spanning users of technology, music informatics, and the deep learning community on the whole.


\section{Dissertation Outline}
\label{sec:outline}
\begin{description}

\item Chapter \ref{chp:context} reviews the current state of affairs in music informatics research, providing context for this work.

\item Chapter \ref{chp:deep_learning} surveys the body of literature in deep learning, outlining core concepts and definitions.

\item Chapter \ref{chp:timbre_sim} explores the application of deep learning toward the development of objective timbre similarity spaces.

\item Chapter \ref{chp:chord_estimation} considers the application of deep learning toward automatic chord estimation, as a means to both improve the state of the art and better understand the task at hand.

\item Chapter \ref{chp:guitar} extends this chord estimation efforts to directly estimate human-readable representations in the form of guitar tablature.

\item Chapter \ref{chp:reproducibility} documents the software contributions resulting from this study, contributing to the greater cause of reproducible research efforts.

\item Chapter \ref{chp:conclusion} concludes this thesis.
There will be tables and chairs, there'll be pony rides and dancing bears, there'll even be a band.

\end{description}

\section{Contributions}
The primary contributions of this dissertation are listed below:

\begin{itemize}
  \onehalfspacing
\item Carrot cake macaroon brownie chupa chups powder sesame snaps bear claw souffle biscuit.
\item Sweet roll chocolate chocolate cake.
\end{itemize}

\section{Associated Publications by the Author}

This thesis covers much of the work presented in the publications listed below:

\subsection{Peer-Reviewed Articles}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\vspace{1em}
\begin{itemize}
\onehalfspacing
\item Sugar plum jelly beans cookie tootsie roll jelly-o.
\item Tootsie roll sugar plum cotton candy pastry chocolate cake pudding oat cake gummi bears.
\end{itemize}

\subsection{Peer-Reviewed Conference Papers}
\vspace{1em}
\begin{itemize}
\onehalfspacing
\item Cheesecake pudding marzipan gingerbread cheesecake oat cake applicake.
\item  Dragee marzipan unerdwear.com powder icing croissant pastry.
\item  Dessert macaroon sweet roll macaroon wafer topping croissant.

\end{itemize}

