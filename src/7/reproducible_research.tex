
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
% the code below specifies where the figures are stored
\graphicspath{{7/figures/}}

\chapter{Workflows for Reproducible Research}
\label{chp:reproducibility}

In recent years, the philosophy of open source software has begun taking root in scientific research, particularly in the field of computer science.
There are several reasons why open research is beneficial to the greater body of human knowledge, but three are of particular value here.
First, sharing code and data allows others to reproduce previous results, a fundamental tenet of the scientific method.
Open source implementations are invaluable for sufficiently complex systems.
It may be near impossible to describe every minute detail in a publication necessary for someone else to replicate the obtained results;
for some works, in fact, the only artifact that can do this unambiguously is the source code itself.
Second, and in a related vein, open research makes is both easier and faster to build upon and extend the previous work of others.
Even in the instance a researcher is able to recreate a published system, the time and effort necessary to get to this point is significant and arguably unnecessary.
Granted, while there is an educational component inherent to the re-implementation of previous work, the situation is akin to long division:
it is certainly valuable to learn \emph{how} to divide by hand, but no one shuns the use of a calculator on a day to day basis.
Lastly, it is a good and responsible act to contribute tools and software back to the larger research community.
All research stands on the shoulders of previous efforts, from improving on a recently published algorithm to the decades-old linear algebra routines doing all its number crunching.
The reality is that no one individual has ever truly solved anything on their own, and sharing the fruits of one's research endeavors serves the common good.

With these motivations in mind, this chapter details the several open source contributions made in the course of this work, culminating in a single code repository used to produce the results contained herein.
These software tools consist of the following:
Section \ref{sec:jams} describes JAMS, a JSON annotated music specification;
Section \ref{sec:biggie} introduces Biggie, an HDF5 interface for interacting with notoriously big data;
Section \ref{sec:optimus} details a user-friendly library for building and serializing arbitrary acyclic processing graphs;
Section \ref{sec:mir_eval} discusses relevant contributions to \texttt{mir\_eval}, a transparent framework for evaluating MIR systems;
and finally, Section \ref{sec:dl4mir} outlines the framework used here to complete this research.


\section{JAMS: A JSON Annotated Music Specification}
\label{sec:jams}

Music annotations ---the collection of observations made by one or more agents about an acoustic music signal--- are an integral component of content-based music informatics methodology, and are necessary for designing, evaluating, and comparing computational systems.
For clarity, the scope of an annotation is constrained to time scales at or below the level of a complete song, such as semantic descriptors (tags) or time-aligned chords labels.
Traditionally, the community has relied on plain text and custom conventions to serialize this data to a file for the purposes of storage and dissemination, collectively referred to as ``lab-files''.
Despite a lack of formal standards, lab-files have been, and continue to be, the preferred file format for a variety of music description tasks, such as beat or onset estimation, chord estimation, or segmentation.

Meanwhile, the interests and requirements of the community are continually evolving, thus testing the practical limitations of lab-files.
Reflecting on this tradition, there are three unfolding research trends that are demanding more of a given annotation format:

\begin{itemize}
\item \textbf{Comprehensive annotation data}:
Rich annotations, like the Billboard dataset\cite{Burgoyne2011expert}, require new, content-specific conventions, increasing the complexity of the software necessary to decode it and the burden on the researcher to use it; such annotations can be so complex, in fact, it becomes necessary to document how to understand and parse the format\cite{De2012parsing}.

\item \textbf{Multiple annotations for a given task}:
The experience of music can be highly subjective, at which point the notion of ``ground truth'' becomes tenuous.
Recent work in automatic chord estimation, both here and in \cite{ni2013understanding}, has shown that multiple reference annotations should be embraced, as they can provide important insight into both system evaluation and the problem formulation itself.

\item \textbf{Multiple concepts for a given signal}:
Although systems are classically developed to describe observations in a single namespace, e.g. chords, there is ongoing discussion toward integrating information across various musical concepts \cite{vincent2010roadmap}.
This has already yielded measurable benefits for the joint estimation of chords and downbeats \cite{papadopoulos2011joint} or chords and segments \cite{mauch2009using}, where leveraging multiple information sources for the same input signal can lead to improved performance.
\end{itemize}


\noindent It has long been acknowledged that lab-files cannot be used to these ends, and various formats and technologies have been previously proposed to alleviate these issues, such as RDF \cite{cannam2006sonic}, HDF5\cite{bertin2011million}, or XML \cite{mckay2005ace}.
However, none of these formats have been widely embraced by the community.
Considering this options, the weak adoption of alternative formats is likely due to the combination of multiple factors.
For example, new tools can be difficult, if not impossible, to integrate into a research workflow because of compatibility issues with a preferred development platform or programming environment.
Additionally, it is a common criticism that the syntax or data model of these alternative formats is non-obvious, verbose, or otherwise confusing.
This is especially problematic when researchers must handle format conversions.
Taken together, the apparent benefits to conversion are outweighed by the tangible costs.


\subsection{Core Design Principles}
\label{subsec:design}

In order to craft an annotation format that might serve the community into the foreseeable future, it is worthwhile to consolidate the lessons learned from both the relative success of lab-files and the challenges faced by alternative formats into a set of principles that might guide the design of a new format.
With this in mind, it is argued that usability, and thus the likelihood of adoption, is a function of three criteria:

\subsubsection{Simplicity}
\label{subsubsec:simplicity}
The value of simplicity is demonstrated by lab-files in two specific ways.
First, the contents are represented in a format that is intuitive, such that the document model clearly matches the data structure and is human-readable, i.e. uses a lightweight syntax.
This is a particular criticism of RDF and XML, which can be verbose compared to plain text.
Second, lab-files are conceptually easy to incorporate into research workflows.
The choice of an alternative file format can be a significant hurdle if it is not widely supported, as is the case with RDF, or the data model of the document does not match the data model of the programming language, as with XML.

\subsubsection{Structure}
\label{subsubsec:structure}
It is important to recognize that lab-files developed as a way to serialize tabular data (i.e. arrays) in a language-independent manner.
Though lab-files excel at this particular use case, they lack the structure required to encode complex data such as hierarchies or mix different data types, such as scalars, strings, multidimensional arrays, etc.
This is a known limitation, and the community has devised a variety of ad hoc strategies to cope with it: folder trees and naming conventions, such as ``\{X\}/\{Y\}/\{Z\}.lab'', where X, Y, and Z correspond to ``artist'', ``album'', and ``title'', respectively\footnote{\url{http://www.isophonics.net/content/reference-annotations}}; parsing rules, such as ``lines beginning with `\#' are to be ignored as comments''; auxiliary websites or articles, decoupled from the annotations themselves, to provide critical information such as syntax, conventions, or methodology.
Alternative representations are able to manage more complex data via standardized markup and named entities, such as fields in the case of RDF or JSON, or IDs, attributes and tags for XML.

\subsubsection{Sustainability}
\label{subsubsec:sustainability}

Recently in MIR, a more concerted effort has been made toward sustainable research methods, which we see positively impacting annotations in two ways.
First, there is considerable value to encoding methodology and metadata directly in an annotation, as doing so makes it easier to both support and maintain the annotation while also enabling direct analyses of this additional information.
Additionally, it is unnecessary for the MIR community to develop every tool and utility ourselves; we should instead leverage well-supported technologies from larger communities when possible.

\subsection{The JAMS Schema}
\label{subsec:schema}

A JAMS object is hierarchically structured to capture all relevant information in a logically organized manner.
The primary record is an \emph{annotation}, of which a JAMS object may contain zero or more.
Annotations are comprised of \emph{observations}, which maintain a set of properties: time, duration, value, confidence, namespace.
Observations have two variants, to better handle \emph{sparse} or \emph{dense} data, such as onsets or melody, respectively.
The semantic context of an observation is specified by its \emph{namespace}, providing information about how the data in the observation should be understood.
Thus a namespace allows for easy filtering and interpretation of the data in an annotation for different music description tasks.

An annotation also maintains a \emph{metadata} object.
Annotation metadata allows for rich descriptions of \emph{who} and \emph{how} a particular record was produced.
Currently, metadata has properties such as \emph{corpus}, \emph{annotator}, \emph{validation}, \emph{curator}, to name a few fields.
Not only does this information make it easier to develop and evaluate systems with an eye to subjectivity, but it enables deeper meta-analyses of the annotations themselves.
This could be achieved by considering the observations made by annotators with different musical backgrounds or degrees of formal training, for example.

In addition to an array of annotations, JAMS objects also maintain a top-level file metadata object.
While annotation metadata sponges information about observer, file metadata tracks global information about the corresponding audio signal, with properties like \emph{title}, \emph{artist}, \emph{duration}, or \emph{indentifiers}.
As there is currently no standard convention for uniquely specifying audio recordings in a global manner, file metadata exists to help link the JAMS object with the appropriate signal.

Finally, \emph{sandboxes} exist in both the top-level and annotation objects to facilitate the growth and extensibility of the format.
These are unconstrained objects that can be used as needed for anything not covered by the formal schema.
This is done in the hope that sandboxes might identify information that could be incorporated into future versions.


\subsection{Python API}
\label{subsec:jams_tools}

To faciliate the use and integration of JAMS in software projects, a Python library is publicly available and under active development\footnote{\url{http://github.com/marl/jams}}.
This application programming interface (API) provides a simple interface for reading, writing, and manipulating the information in a JAMS object.
Many common datasets are also provided in this format to further encourage adoption.
Complementing the creation and use of human annotations, JAMS makes it easier to operate on this information, such as augmenting audio and annotations in parallel \footnote{\url{http://github.com/bmcfee/muda}}.


\section{Biggie}
\label{sec:biggie}

Audio signals, and the various time-aligned representations they might take, are high dimensional data, and it is useful to develop ways of capturing signal level information and associating it all with the same conceptual object, i.e. a recording.
Conceptually, \emph{biggie}\url{http://github.com/ejhumphrey/biggie} is the high-dimensional, signal-level equivalent to JAMS, introducing two basic objects.
An \emph{entity} is a struct-like object designed to keep various numerical representations together.
These objects are then freely written to and read from a \emph{stash}, a persistent, i.e. on-disk, key-value store.
Here, each entity is given a unique key, making it easy to align a dictionary of signals with a dictionary of annotations.
Biggie also allows random access, facilitating bootstrap sampling and stochastic training\footnote{\url{https://github.com/bmcfee/pescador}}.
Leveraging the h5py\footnote{\url{http://www.hdfgroup.org/HDF5/}} library under the hood and based on HDF5\footnote{\url{http://www.hdfgroup.org/HDF5/}}, biggie scales to arbitrarily large datasets;
however, as it shares a common interface with common dictionaries, the memory footprint scales gracefully with available computational resources.

% Notably, HDF5 is a cross-language data format designed for storing large amounts of numerical data in a hierarchical manner.

% \subsection{Entities}
% \label{subsec:entities}

% Carrot cake marzipan gummies croissant oat cake pie candy canes chocolate.
% Sugar plum jelly beans oat cake cake jujubes jelly chupa chups biscuit \ref{fig:muffin}.
% Croissant cotton candy chupa chups.
% Cheesecake tart bear claw brownie sugar plum.

% \subsection{Stash}
% \label{subsec:stash}

% Carrot cake marzipan gummies croissant oat cake pie candy canes chocolate.
% Sugar plum jelly beans oat cake cake jujubes jelly chupa chups biscuit \ref{fig:muffin}.
% Croissant cotton candy chupa chups.
% Cheesecake tart bear claw brownie sugar plum.

% \subsection{Python API}
% \label{subsec:biggie_tools}


\section{Optimus}
\label{sec:optimus}

% What is the problem
Theano is powerful, and repeating experiments is necessary, but serialization is difficult.
The common approach in Python, known as ``pickling'', is sensitive to code changes, and thus something pickled previously may not work in the future.
Unsuitable for projects under active development.
Additionally, designing every neural network in Theano can be time-consuming, and does offer the most friendly user interface.
This is especially true when attempting to work with non-standard architectures, such as guitar fretboard models or pairwise training strategies.

% How does optimus solve these problems
Optimus \url{http://github.com/ejhumphrey/optimus} is a direct effort to solve both of these problems in a flexible, yet user friendly, manner.
To simplify the creation, training, and application of neural networks, common building blocks are provided as natively serializable objects that can be wired together in an graphical manner.
% Inputs, outputs.
First, optimus allows the user to define any number of named inputs and outputs, making it easy to adapt to various problems.
% Nodes and math
Then, using a large collection of \emph{nodes}, arbitrary acyclic, i.e. no loops, graphs can be architected, making use of common subfunctions like the ``Affine'' or ``Conv3D'' operations.
% Losses
While nearly any loss function can be realized from these basic building blocks, a handful of standard \emph{losses} are provided, simplifying design.
The topology between these parts is given by a routing table, and passed off to a \emph{graph}, which connects the dots and returns an optionally trainable function.
Furthermore, given the flexibility to define topologies in a processing graph, it is simple to explore a variety of modifications, such as layerwise hyperparameters or tapping various intermediary representations as outputs.

In additiona to the user-facing advantages, robust serialization is achieved by expressing processing graph definitions as JSON and archives of C-arrays.
Though currently unsupported, this offers the additional benefit that it would be straightforward to optimus models across languages in the future.
Finally, as parameter assignments are expressed through named nodes and fields, it is trivial to not only save parameters but easily initialize them by arbitrary means, such as pre-training or using supervised learning on hand-crafted functions.


\section{mir\_eval}
\label{sec:mir_eval}

Much of the research in Music Information Retrieval (MIR) involves the development of systems that process raw music data to produce semantic information.
The goal of these systems is frequently defined as attempting to duplicate the
performance of a human listener given the same task~\cite{downie2003toward}.
A natural way to determine a system's effectiveness might be for a human to study the output produced by the system and judge its correctness.
However, this would yield only subjective ratings, and would also be extremely time-consuming when evaluating a system's output over a large corpus of music.

Instead, objective metrics are developed to provide a well-defined way of computing a score which indicates each system's output's correctness.
These metrics typically involve a heuristically-motivated comparison of the system's output to a reference which is known to be correct.
Over time, certain metrics have become standard for each task, so that the performance
of systems created by different researchers can be compared when they are evaluated
over the same dataset~\cite{downie2003toward}.
Unfortunately, this comparison can be confounded by small details of the implementations or procedures that can have disproportionate impacts on the resulting scores.

% MIREX is the standard, but it's not community-developed, not transparent, not well-documented, uses multiple languages, is coupled to NEMA, not easy to use, dependencies, not used outside of MIREX, etc.
For the past 10 years, the yearly Music Information Retrieval Evaluation eXchange
(MIREX) has been a forum for comparing MIR algorithms over common datasets~\cite{downie2008music}.
By providing a standardized shared-task setting, MIREX has become critically useful for tracking progress in MIR research.
MIREX is built upon the Networked Environment for Music Analysis (NEMA)~\cite{west2010networked}, a large-scale system which includes exhaustive functionality for evaluating, summarizing, and displaying evaluation results.
The NEMA codebase includes multiple programming languages and dependencies (some of which, Matlab, are proprietary) so compiling and running it at individual sites is nontrivial.
%
%Due to its scale, characteristics, and intended use,
In consequence, the NEMA system is rarely used for evaluating MIR algorithms outside of
the setting of MIREX~\cite{downie2008music}.
Instead, researchers often create their own implementations of common metrics for evaluating their algorithms.
These implementations are thus not standardized, and may contain differences in details, or even bugs, that confound comparisons.

These factors motivate the development of a standardized software package which implements the most common metrics used to evaluate MIR systems.
Such a package should be straightforward to use and well-documented so that it can be easily adopted by MIR researchers.
In addition, it should be community-developed and transparently implemented so that all design decisions are easily understood and open to discussion and improvement.

\subsection{Chords}

Despite being one of the oldest MIREX tasks, evaluation methodology and metrics for automatic chord estimation is an ongoing topic of discussion, due to issues with vocabularies, comparison semantics, and other lexicographical challenges unique to the task~\cite{pauwels2013evaluating}.
One source of difficulty stems from an inherent subjectivity in ``spelling'' a chord name and the level of detail a human observer can provide in a reference annotation~\cite{ni2013understanding}.
As a result, a consensus has yet to be reached regarding the single best approach to comparing two sequences of chord labels, and instead are often compared over a set of rules, i.e Root, Major-Minor, and Sevenths, with or without inversions.

To efficiently compare chords, a given chord label is first separated into its
constituent parts, based on the syntax of~\cite{harte2010towards}.
For example, the chord label \texttt{G:maj(6)/5} is mapped to three pieces of information: the root (``G''), the root-invariant active semitones as determined by the quality shorthand (``maj'') and scale degrees (``6''), and the bass interval (``5'').
Based on this representation, an estimated chord label can be compare with a reference by defining a comparison function between these invariant representations.
Any encoded chords that are deemed to be ``out of gamut'' return a negative score to be easily filtered.

Track-wise scores are computed by weighting each comparison by the duration of its interval, over all intervals in an audio file.
This is achieved by forming the union of the boundaries in each sequence, sampling the labels, and summing the time intervals of the ``correct'' ranges.
The cumulative score, referred to as \emph{weighted chord symbol recall}, is tallied over a set audio files by discrete summation, where the importance of each score is weighted by the duration of each annotation~\cite{cho2013mirex}.


\section{Deep Learning for Music Informatics}
\label{sec:dl4mir}

The aggregate code base used herein, referred to as \emph{dl4mir}\url{http://github.com/ejhumphrey/dl4mir}, is also made available.
This resource provides shell scripts for feature extraction, training, and evaluation.
All reported results and figures provided in this document are contained in iPython notebooks for reference and repeatability.
Effort has been made to minimize dependencies and remove vestigial code.


\section{Summary}
\label{sec:summary}

Everything necessary to repeat all research reported here is available online.
