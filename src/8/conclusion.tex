\graphicspath{{8/figures/}}
\chapter{Conclusion}
\label{chp:conclusion}

This thesis has explored the application of deep learning methods to the general domain of automatic music description, focusing on timbre similarity and automatic chord estimation.
Encouraging performance is obtained in both areas, advancing the state of art in the latter, while providing deeper insight to the tasks at hand.
These observations encourage the slight reformulation of chord estimation as a representation learning, rather than a classification, problem, resulting in a high performing system with myriad practical benefits.
This chapter summarizes the main contritributions of this work, and offers perspectives for the future, including an assessment of outstanding challenges and the potential impact of continued research in this domain.

\section{Summary}

Automatic music description is at the heart of content-based music informatics research.
This is necessary for problems where manual annotation does not scale, such as acoustic similarity, as well as problems where most people lack the musical expertise to perform the task well, such as transcription.
While this topic is independently valuable, it would seem that progress is decelerating, and thus any efforts to correct this course must first determine why.
In Chapter \ref{chp:context}, common practice in automatic music description was revisited, leading to the identification of three deficiencies worth addressing:
hand-crafted feature design is not sustainable, shallow architectures are fundamentally limited, and short-time analysis alone fails to capture long-term musical structure.
Deep architectures and feature learning were shown to hold promise in music analysis tasks, evidenced both conceptually and by its growing success, motivating the exploration of deep learning in automatic music description.

At this point, it was necessary to consider what is ``deep learning'', and why is this an option now?
In Chapter \ref{chp:deep_learning}, the history of the field was first re-examined, showing that after an over-hyped introduction, neural networks languished through the latter part of the 20th century.
This period of skepticism and disinterest gave technology time to catch up to the theory, and after a serious of significant research contributions, deep learning made a triumphant return to the fore of computer science, toppling longstanding benchmarks seemingly overnight.
While this has brought about a second wave of hype and interest, it also encouraging the curation of a more established theory of deep networks.
As reviewed, the modern practice of deep learning consists of a handful of modular processing blocks, strung together in differentiable functions and numerically optimized to an objective function via gradient-based methods, complemented by a growing suite of practical tricks of the trade.

Having reviewed the modern core of deep learning, this work shifted focus in Chapter \ref{chp:timbre} to explore these methods directly.
As a first inquiry, a deep convolutional network was applied to the task of timbre similarity, achieving three goals:
the model is able to learn relevant signal-level features that give rise to source identification;
the resulting output space is organized in a semantically meaningful way;
and the smoothness of the space is indicated by error analysis.
The approach presented here also offers novel extensions to previous efforts in pairwise training, achieving extremely robust representations despite a considerable reduction in dimensionality.
And perhaps most importantly, these results are obtained without the need for costly subjective pairwise ratings of content.

Whereas timbre similarity served as a relatively constrained problem, Chapter \ref{chp:chord_estimation} sought to test the limits of deep learning as applied to automatic chord estimation, a well-established music informatics challenge.
Competitive performance is achieved with a deep convolutional neural network, evaluated in both a conventional and large-vocabulary variant of the task.
Somewhat more interestingly, rigorous error analysis reveals that efforts in automatic chord estimation are converging to a glass ceiling, due in large part to the objective formulation of an often subjective experience.
The problems caused by the tenuous nature of ``ground truth'' annotations are exacerbated by efforts to treat chord estimation as a flat, rather than hierarchical, classification task.
Therefore, the singlemost critical advancement facing the topic of automatic chord estimation is a re-evaluation of the task the community is attempting to solve and the data used to do so.

Despite these difficulties, the chord estimation data is leveraged to ask a slightly different question: can a model be built to automatically predict chords as guitar tablature?
Therefore, in Chapter \ref{chp:guitar}, again using a deep convolutional architecture, global performance statistics are improved over the general chord estimation system, while offering significant practical benefits.
In addition to being a high-performing system, the fretboard estiamtions are immediately human-readable and thus attractive from a user experience perspective.
Such a representation is also advantageous from a data collection, correction, and validation standpoints, significantly reducing the degree of prerequisite skill necessary to contribute annotations.

Finally, the various open source software artifacts developed in the course of this research are introduced and detailed in Chapter \ref{chp:reproducibility}:
\texttt{jams}, the structured music annotation format designed for multiplicity of both annotator perspective and task namespace;
\texttt{biggie}, an approach to managing large collections of numerical data for training stochastic learning algorithms;
\texttt{optimus}, a user-friendly library for describing and serializing trainable processing graphs;
\texttt{mir\_eval}, a suite of evaluation tools for benchmarking music description algorithms;
and finally \texttt{dl4mir}, a common framework for the systems and results presented here.


\section{Perspectives on Future Work}
\label{sec:future}

Based on the work performed herein and observations made in the process, this section offers several perspectives on deep learning, music informatics, and the intersection between them, in the spirit of helping guide future work.


\subsection{On Architectural Design in Deep Learning}

Among the most common questions currently facing the application of deep learning to any problem is that of architectural design.
``How many layers,'' one might ask, ``or how many kernels are necessary for this to work?
Should I use convolutions, or matrix products, or something else altogether?
And furthermore, if and when it does actually work, what on earth is it doing?''
Admittedly, the combination of numerical optimization and extremely versatile functions often results in systems with opaque mid-level representations, earning deep networks the reputation as ``black boxes'' and the study of them a ``dark art''.
However, while these enigmatic functions might cause understandable confusion, the design of deep architectures is not necessarily devoid of intution.

% Simply train the systems we've already got
But where to start?
The simplest way one might begin to explore deep learning for some problem of choice is to build some previously published algorithm and use gradient descent to fine-tune the hand crafted weights.
There are countless MIR systems could be reformulated in the deep learning framework, such as onset detection, instrument identification, or pitch estimation.
Most importantly, doing so eliminates the need to compare minor implementation details, like specific hyperparameters or window coefficients;
just learn it and let it all come out in the wash.
Addtionally, introducing the process of learning to classic music informatics systems makes it easier to \emph{combine} multiple systems to reap the benefits of model averaging.
The key takeaway here is the notion that good architectures already exist for some problems, and that better performance can be obtained by using numerical optimization to expand the space of parameters considered.

% Or explore new ones
Critically, these lessons and practices transcend known problems to new ones.
As demonstrated with the fretboard achitecture of Chapter \ref{chp:tabbing}, systems can be quickly constructed by appropriately constraining the behavior.
Since a guitar has six strings, and each can only be active in one place, it makes sense to model each as a probability surface.
That said, there is much more could be done here.
Perhaps transition constraints could be imposed, such that the model would prefer common chord shapes, or positional constraints, whereby nearby frets are perferred to large jumps.
In this manner, end-to-end systems can be designed and developed at a high level, and numerical optimization can be leveraged to work out the fine details.
Furthermore, while learning can discover useful features that were previously overlooked or not considered, this advantage is amplified for new challenges and applications that do not offer much guiding intuition.
For tasks like artist identification or automatic mixing, it is difficult to comprehend, much less articulate, exactly what signal attributes are informative to the task and how an implementation might robustly capture this information.

% Going beyond problems that already provide some structural intuition, an advantage of deep learning is it's substantial flexibility.

% Design is a skill to be learned.
% Various design decisions, such as model selection, data pre-processing, and carefully choosing the building blocks of the system, can impact performance on a continuum from negligible differences in overall results to whether or not training can, or will, converge to anything useful.
% Likewise, the same kind of intuition holds for adjusting the various hyperparameters ---learning rate, regularizers, sparsity penalties--- that may arise in the course of training.
% The important thing to recognize though is that these are skills to be learned.
% Using deep learning presents a design problem not altogether different from the one with which we are familiar, but the approach is overtly more abstract and conceptual, placing a greater emphasis on high-level decisions like the choice of network topology or appropriate loss function.

% Abstraction
Thus, deep learning, as an approach to system design, transforms the challenge from ``how do I \emph{implement} the desired behavior?'' to ``how do I \emph{achieve} the desired behavior?''
The nature of this advantage is illustrated by the relationship between programming in a high-level language, like Python, and a low-level one, like assembly.
Technically speaking, both can be used to the same ends, but high-level languages allow for faster development of complex systems by abstracting away the minute details, like memory management or the laborious task of moving data around registers.
% Knowledge of low-level operation is often critical to success in its higher level counterpart, but powerful languages do not absolve the developer of design.
In both cases, precise control is traded for power, leaving the developer to focus on the task at hand with greater speed and efficiency.
Note, however, that abstraction doesn't eliminate the need for sound architecture, only the need to worry about certain facets.
The fundamental design challenge is the same, but operating at a higher level of abstraction allows the deep learning researcher to build bigger systems faster.

% Takeaway: it's not really guess work, there's still work to be done.
Therefore, it is worthwhile to note that music informatics researchers are quite proficient at leveraging domain knowledge, engineering acumen, and a bit of intuition to architect signal processing systems;
how many principal components should one keep of a feature representation?
what is a suitable window size for a Fourier transform?
how many subbands should a given filterbank have?
The same intuition can and should be used to design deep networks, as discussed in the learning of chroma, the design of a tempo estimation system, or constructing instrument-specific models.
% Digital signal theory is still relevant,
Ultimately, the process of designing a deep architecture is as arbitrary or intentional as one makes it; it's only guesswork if you're guessing.


\subsection{Practical Advice for Fellow Practitioners}

%
While the previous discussion hopefully serves to address some of the mystery inherent to deep learning, it certainly entails the disclaimer of ``your mileage may vary.''
The following are a handful of guidelines accumulated in the course of research;
far more suggestion than direction, they have served well in practice.

\begin{enumerate}

\item \textbf{Data is fundamental}:
The data-driven researcher will live and die by the quality of data available.
It is widely held that lots of weakly labeled data will often trump a small amount of strongly labeled data.
The cousin of this sentiment is once you have enough data, everything will come out in the wash.
Take care to note that though this may hold for training, with caveats, the inverse is true for evaluation.
Furthermore, beware obscure biases in data.
Greedy optimization will happily yield bad solutions because of oversights in the curation of training data.
This is particularly true of regression problems.
It is possible to compensate for biased data in classification via uniform class presentation or likelihood scaling, but this can be far less obvious for continuous valued outputs.


\item \textbf{Design what you know, learn what you don't}:
As mentioned, neural networks offer the theoretical promise of the universal approximation theorem, but realizing such general behavior is far from trivial.
It is therefore crucial to leverage domain knowledge where possible.
This will typically take two forms:
one, simplify the learning problem by removing degrees of freedom known to be irrelevant to the problem;
two, constrain the learning problem to encourage musically plausible solutions.
If loudness doesn't impact one's ability to recognize chords, for example, the data should probably be normalized.
Music informatics researchers have a diverse background on which to draw, and this knowledge can be incorporated into the model or training strategy.
Notably, curriculum learning will likely become a much larger topic in the near future, and much can be incorporated from music education and pedagogy in this process.


\item \textbf{Over-fitting is your friend}:
Long heralded as the boon of deep networks, over-fitting is arguably a \emph{good} sign, and far more desirable behavior than the inverse.
Simply put, if a deep network is unable to over-fit the training data, something is likely wrong.
This is often due to one or more of the following three issues;
one, it is indicative of a problem with the data, e.g. the observations and targets are uncorrelated or, worse, conflicting;
two, the chosen model lacks the representational power to fit the training data;
or three, and most problematic, the learning problem is poorly posed and optimization is getting stuck in a bad local minima.
The methods for dealing with such issues are not so well codified, but consist of data cleaning, exploring ``bigger'' models, unsupervised pre-training, changing the loss function, etc.; that said, the efficacy of such approaches will vary case by case.


\item \textbf{Get good mileage out of greedy optimization}:
Gradient descent and other such greedy methods are certainly prone to bad local minima, but it is not impossible to take active measures to discourage unfortunate solutions.
% Encourage good behaviour and discourage the bad.
Additionally, it may be easier to define the kinds of things a model \emph{shouldn't} do than the things it should.
For example, a fretboard prediction network could incorporate a penalty whereby ``unplayable'' chord shapes incur significant loss to help keep outputs in a realistic space.


\item \textbf{The gap between ``real'' and synthetic music is closing}:
As more modern music transitions to a digital environment, the difference in quality between a real sound recording and one synthesized for research purposes is converging to zero.
Generally speaking, samplers, synthesizers, and other music production software are underutilized in data-driven music research.
These high quality tools can also be used for data augmentation to make algorithms robust to irrelevant deformations, such as perceptual codecs, background noise, tempo modulation, or pitch shifting.
By generating an unprecedented amount of realistic training data, can we functionally solve tasks such as onset detection, pitch detection, or tempo estimation?

\end{enumerate}


\subsection{Limitations, Criticisms, and a Healthy Dose of Realism}

% Deep learning is reaching toxic levels of trendiness
There is an empirical sense of skepticism regarding neural networks among many in the various perceptual AI communities, including MIR, due in no small part to the exaggerated promises of very early research, and popular opinion has not evolved with the science.


% Part of a larger arc
After an impeccably rocky start, neural networks are finally having their day in the sun.
Shown in Figure \ref{fig:deephype}, it is interesting to consider that the path of deep learning has closely followed Gartner's technology Hype Cycle.

\begin{figure}
\begin{centering}
\includegraphics[width=0.6\textwidth]{deephype}
\caption{Gartner Hype cycle of neural networks.}
\label{fig:deephype}
\end{centering}
\end{figure}

If you're learning everything, where's the research?

\emph{Is deep learning some magic bullet?}
Of course not.
\emph{Is it intelligent?}
Hardly.
But is it useful?
Can it accelerate the process of system design and implementation?
Can it allow the clever researcher to quickly vet ideas and rapidly prototype systems?
The answer to all of these is ``yes''.
Once out from under the shadow of skepticism, deep learning is but a tool ---a powerful tool, but a tool nonetheless--- to include in the toolbelt of the information science practitioner.
Settling in as another computational tool in the belt (PCA or SVMs), following the hype cycle; we are in the path to productivity.
Have a better idea of how they can work.

There are many things it is not:
Intelligent
Magic
A dark art
A black box
It is, however, a few things:
A powerful approach to non-linear system design
A possible and / or partial answer to aforementioned problems
A close extension of common MIR methods

What have we actually learned from previous struggles? Are we at risk of repeating the past?

It is important to have reasonable expectations for what can be achieved with deep learning and neural networks, lest another winter comes knocking.
Semantic gap, the limitation of audio signal processing systems whereby the information necessary to make some decision does not truly reside in the signal.
Wiggins, offers ``the mysterious thing that is Music is an abstract and intangible cultural construct, which does not have physical existence in itself, but which is described by all three of these representational domains'', being the acoustic, the auditory, and the graphemic (notated) \cite{Wiggins2009}.
``the fundamental source of Music --—that without which Music cannot exist—-- is in the mind: if no mind is involved, there is no Music, but only sound.''


Fantastic non-linear models of deterministic relationships.
Perfect for models of physical systems.
Build systems that \emph{behave} intelligently without \emph{being} intelligent.
Heider and Simmel \cite{Heider1944} has fascinating implications for machine perception.
Intelligence stems from a sense of self.
Deterministic deep networks may represent a snapshot of an intelligent agent, an instantaneous perspective, but
Recursive networks are promising, both for introducing arbitrary time-scales of memory as well as notions of expectation.
Priming, context, expectation, etc.

% Takeaways:
Deep learning is a powerful tool; no more, no less.
No free lunch, still requires design and research and work
Explore new problems that lack intution
Revisit problems that have it.
At least use numerical optimization to fine tune current systems, like chroma learning, onset detection, tempo estimation.
Interpret current systems as deep networks and then apply the same tools, such as learning, bagging, etc.


\subsection{On the Apparent Rise of Glass Ceilings in Music Informatics}

One of the motivating factors of this work was to understand and potentially address the increasing prevalence of diminishing returns in various music description tasks, like chord estimation, genre classification, or mood prediction.
The main hypothesis resulting from an initial survey was the idea that common approaches to system design were inadequate, and another approach to system design, i.e. deep learning, might afford significant performance gains.
However, one of the most significant outcomes of this work is in some sense the most unexpected:
subtle deficiencies in methodology may be contributing as much or more to unsatisfactory results than the algorithms or approaches used to achieve them.

This finding echoes a recent but fledgling trend in music informatics of critically assessing how the scientific method is applied to machine listening tasks, with meta-analyses of genre recognition \cite{Sturm20inf}, rhythmic similarity \cite{Esparza2014}, and music segmentation \cite{Neito2015}, to name a few.

Conventionally, the methodology for computational modeling of music description consists of five steps:

\begin{enumerate}
\item Define the problem.
\item Collect data.
\item Build a solution.
\item Evaluate the model.
\item Iterate.
\end{enumerate}

% \begin{enumerate}
% \item Define the problem.
% \item Collect data.
% \item Form a hypothesis.
% \item Conduct experiments to test the hypothesis.
% \item Interpret and analyze the experimental results.
% \item Repeat.
% \end{enumerate}

Broken out in this way, the larger narrative of content-based music informatics is an simple story to tell.
Though a young field, the majority of current research has converged to a handful of established tasks, as evidenced by the set conducted at MIREX.
Labeled music data is notorious difficult to amass in large quantities, but resouces have grown steadily, if piecemeal, for those well-worn problems.
In cases where it has not, researchers are faced with one of two options:
curate the data themselves, or adapt an existing dataset to their problem.
Having built a solution ---otherwise known as the ``fun'' part--- it is necessary to benchmark a proposed algorithm against previous efforts.
However, to make such comparisons fairly, it is typically necessary to compute the same metrics over the same data, as the systems themselves are seldom made public.
Thus, most research efforts today focus almost exclusively on (3) and (5), adopting or otherwise accepting the other three.

It is critical to note, though, that these other methodological stages --- problem formulation, data curation, and evaluation--- have developed naturally over time at the community level, based not on globally optimal design but rather a combination of evolving understanding, inertia, and convenience.
At this point, it serves to return to an initial question posed by this work:
why \emph{are} music description systems yielding diminishing returns?
The findings of this work, particularly in the space of automatic chord estimation, corroborate the growing trend that perhaps the biggest problem facing content-based music informatics is one of methodology.

Leveraging previous work for perspective, it is curious to return to these methodological questions.
Consider the case of automatic chord estimation.
What is the scope of the problem are we really trying to solve?
``Can an agent provide acceptable chord transcriptions?'' is a very different question from ``Can an agent reproduce \emph{these} chord transcriptions?''
Analysis of the Rock Corpus transcriptions showed that comparing the outputs of two expert musicians can achieve a ``yes'' and ``no'' respectively.
How do we know when we have accomplished our goals?
Does weighted chord symbol recall with different comparison rules truly correspond to subjective experience?
The difference in harmonic function between a \texttt{I:7} and a \texttt{I} does not match the difference between a \texttt{V:7} and a \texttt{V}, for example.
Does the data reflect these requirements?
Chord annotations are consist of single perspectives from myriad annotators, and we don't know who did what.
It is inconceivable that all annotators are using the chord labels the same way.
% Ultimately, all research is bounded by the quality of the data available for development and evaluation

At this point in the trajectory of music informatics, it is conceivable that most well-worn tasks could use a reassessment of common methodology.
Diminishing returns is the result of not asking the right question and not using the right data to answer it.


\subsection{On the Importance of Music in AI Research}

% AI at a human level
Artificial intelligence is a lofty goal.
As discussed, music is fundamentally human, quintessentially intelligent.
For all the evolutionary adaptations in nature, music is a uniquely
human phenomena, spanning creativity, planning, memory, and meaning.
Thus, a proposition: one cannot meaningfully make machines understand music without understanding humanity better as a result.

% AI and music at a practical research level
Music is a different ballgame, differs from speech, vision, and natural
language processing in key ways.
The only real study of ``art'' in machine learning disciplines.
Closest things are sentiment analysis and humor, which are small subsets of NLP.
Presents opportunities unique to the domain.

% Some near-field opportunities
That said, one of the more enticing challenges facing music informatics is that time-frequency representations, though two-dimensional, are fundamentally \emph{not} images.
When considering the application of deep learning to MIR problems, it is prudent to recognize that the majority of progress has occurred in computer vision.
While this gives our community an excellent starting point, there are many assumptions inherent to image processing that start to break down when working with audio signals.
One such instance is the use of local receptive fields in deep learning, common in CNNs and, more recently, tiled networks \cite{Le2010}.
In these architectures, it is known that the strongest correlations in an image occur within local neighborhoods, and this knowledge is reflected in the architectural design.
Local neighborhoods in frequency do not share the same relationship, so the natural question becomes, ``what architectures \emph{do} make sense for time-frequency representations?''
As we saw previously, CNNs yield encouraging results on time-frequency representations of audio, but there are certainly better models to be discovered.

% Some longer term ones
Recursive networks for memory and expectation
Agency and self-awareness
Computational creativity
